Unsupervised learning of depth and ego-motion from video

[摘要]
    我们提出了一个无监督学习框架，它可从非结构化（即：未进行数据标注）的单目视频序列中估计出单目场景的深度和相机位姿。和最近[10,14,16]的工作相同，我们使用了一个端到端的学习方法，用视场合成(view synthesis)作为信号监督。和之前的工作相比，我们的方法是完全无监督的，只需要用单目视频序列训练即可。我们的方法运用了单视图深度(single-view depth)和多视图位姿网络(multi-view pose networks)，并用计算出的深度和位姿将临近的视图扭曲到目标上，作为loss()。网络在训练的时候通过loss耦合，但在测试时可以独立应用。在KITTI数据组以实验为依据的评估也证明了我们方法的有效性：1）单目深度估计效果很好，其效果与使用ground-truth位姿/深度的监督学习方法的效果差不多。2）该方法的位姿估计效果和基于SLAM的位姿估计效果差不多。






















